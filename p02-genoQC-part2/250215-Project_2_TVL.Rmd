---
title: "HUGEN 2072 Project 2"
author: "Tianze (Vincent) Luo adapted"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: 
        collapsed: no
    df_print: paged
    number_sections: no
    theme: cosmo
editor_options:
    chunk_output_type: inline
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

# Instructions
Below is a tutorial consisting of a mostly-completed QC pipeline and some prompts.

Project 1 has three components:

* **Scripting/coding**: read through this file and complete the pipeline by contributing your code *where indicated*.

* **Narrative**: knit the completed .Rmd to a code-integrated HTML report of your QC process and decisions.

  * Your report must answer all the questions and perform all the tasks indicated in the instructions/prompts given for each step.

  * You must submit a successfully-knitted HTML file and the `.Rmd` in order to earn a passing grade for this project.

  * Set up your report to flow like an actual document you might show your supervisor to summarize the QC project, emphasizing what was done at each step rather than the code used to do it (e.g., how many samples/SNPs were filtered out at a given step?)

  * **Submit your .Rmd and HTML to Canvas**

* **Presentation**: you will make a 10Â min (maximum) recording of yourself with Panopto in which you summarize this QC pipeline. Instructions will given on Canvas.

In each Part of this project you will implement one of the main steps of cleaning genotyping array data in a small dataset (note that we left a few steps out). You'll be shown how to use functions from the `{GWASTools}` package, and you'll supply a little of your own code to complete the pipeline that's been provided. At each step, you may be asked to create a filter for the data, to address errors/discrepancies, etc. Then for each step you'll make a short report (a few sentences and figures) explaining what you did.

Note that "sample" and "scan" are used interchangeably throughout this assignment, but that these are NOT synonymous with subject/participant/individual/etc. In this assignment, "SNP" and "probe" are used interchangeably, but in other contexts you should always remember the distinction.

**Since the pipeline below is incomplete, some of the R code chunks are set to `eval=FALSE` so that knitting to HTML will succeed. You will need to change them to `eval=TRUE` as you progress so that your knitted document shows the results of running each chunk.**

**It is expected that you will copy this file somewhere to your directory on the CRC cluster so that you can use the RStudio Server, where all the packages you need have been installed already.**

<br>

## Part 0 - Setup and Introduction to Annotation Data Frames

First, load the packages we'll be using.

```{r load_packages, message=F, eval=TRUE}
rm(list=ls())

# Load the required packages for the project (Install them if necessary)
library("GWASTools", quietly = TRUE)
library("GWASdata", quietly = TRUE)
library("SNPRelate", quietly = TRUE)

library(tidyverse, quietly=TRUE)

# Close any open GDS files before proceeding (think of this as starting off with
# a 'blank slate')
showfile.gds(closeall = T, verbose = T)

```

The array data (genotypes, intensities, and BAF/LRR information) for this project are contained in several GDS files; accompanying SNP and scan annotation are also provided as an `.RData` file.

The probe/SNP annotation is stored in an object called a SNP annotation data frame, and the sample-level annotation is stored in a scan annotation data frame. Each of these objects is similar to an ordinary data frame. More precisely, a data frame is embedded within each. There is also accompanying metadata. 

To access the data and metadata, the `{GWASTools}` package provides several functions. Three basic functions you should familiarize yourself with are: 

- `getAnnotation()`/`pData()` (extracts a standard data frame containing the annotation)
- `getMetadata()`/`varMetadata()` (extracts a data frame of variable descriptions)
- `getVariableNames()`/`varLabels()` (extracts a vector of just the variable names)

You can also view a variable in one of these objects by using `$`, as you would for an ordinary data frame. You can also add new variables, but you need to be careful to update the metadata as well. Since we will be adding new variables in the process of cleaning our data, the following chunk of code shows you how to do this. Then you will practice looking at the annotation, and your task is to answer some questions about this data set.

First, load the annotation data (`annotation_data.RData`) that was provided with this project. **You need to supply the path to this file.**

```{r load_annotation, eval=TRUE}

# Load the probe (SNP) and sample annotation data frames, which have been saved in an .RData file
path_to_annotation_data <- "/ix1/hugen2072-2025s/p1/annotation_data.RData"
load(path_to_annotation_data, verbose = TRUE)

# List the loaded objects
ls()
typeof(scanAnnot); typeof(snpAnnot)

```

Here's a toy example showing you how to work with annotation data frames. **Read this carefully, since you'll need to do this throughout the assignment.**

```{r annotation_data_frame_example, eval=TRUE}

### How to add a new variable to an annotation data frame ###

#   Make a new copy of the SNP annotation (just for this example)
snp_annodf_temp <- snpAnnot

#   Notice that printing the object isn't that helpful
snp_annodf_temp

## Step1
#   So extract the annotation itself (this is the 'normal' data frame embedded
#   in the SNP annotation data frame object). Now you can see the SNP-level
#   annotation
snp_data_temp <- getAnnotation(snp_annodf_temp)
head(snp_data_temp)

#   Add a new column to the annotation (an integer dummy variable)
snp_data_temp$dummy <- 1:nrow(snp_data_temp)

#   Now update the scan annotation object itself by replacing the what was in
#   the annotation "slot"
pData(snp_annodf_temp) <- snp_data_temp

#   You can see that the new column has been added
head(pData(snp_annodf_temp))


## Step2
#   Extract the metadata so that it can be updated
meta_temp <- getMetadata(snp_annodf_temp)
meta_temp

#   Add a new row titled "dummy" with an appropriate labelDescription (note that
#   the metadata is a data frame with named rows but one column)
meta_temp["dummy", "labelDescription"] <- "This is a dummy variable"

#   Finally, replace the old metadata with the new metadata
varMetadata(snp_annodf_temp) <- meta_temp


## Step3
#   Look at the data and metadata to make sure there the dummy variable has been
#   added
head(getAnnotation(snp_annodf_temp))
getMetadata(snp_annodf_temp)

#   Remove the temp files
rm(snp_annodf_temp, snp_data_temp, meta_temp)

```

**Conclusion**: update Annotation data -> update metadata

<hr>

Now we use `GdsGenotypeReader()` and `GdsIntensityReader()` to open the gds files that contain the array data. Then use `GenotypeData()` and `IntensityData()` to combine them with the SNP and sample annotation, since the functions we'll be using later require this information to be "packaged" together.

```{r load_array_data, eval=TRUE}
##1
#   Get the genotypes from a gds file
genofile <- system.file("extdata", "illumina_geno.gds", package = "GWASdata")
gds_geno <- GdsGenotypeReader(genofile)

#   Combine the genotypes with the sample and SNP annotation
genoData <- GenotypeData(gds_geno, snpAnnot = snpAnnot, scanAnnot = scanAnnot)
genoData


##2.1
#   Get the intensity data from a gds file
qxyfile <- system.file("extdata", "illumina_qxy.gds", package = "GWASdata")
gds_qxy <- GdsIntensityReader(qxyfile)

#   Combine with the sample and SNP annotation
qxyData <- IntensityData(gds_qxy, snpAnnot = snpAnnot, scanAnnot = scanAnnot)
qxyData

##2.2
#   Get the BAF/LRR data from a gds file
blfile <- system.file("extdata", "illumina_bl.gds", package = "GWASdata")
gds <- GdsIntensityReader(blfile)

#   Combine the BAF/LRR data with the sample and SNP annotation
blData <- IntensityData(gds, snpAnnot = snpAnnot, scanAnnot = scanAnnot)
blData

```

## Part 0 - Report

Using the functions introduced above to help you, briefly describe the dataset in a few sentences. Answer the following questions. Whatever code you use to help answer these questions can go in the empty chunk that follows.

* What is the difference between the scanID and subjectID variables? Why are they both provided?

* How many families are represented, and how many samples are from each family?

* How many samples are of each sex?

* How many samples are from each population group?

* How many samples are there? How many people did they come from?

* How many SNPs are there?

* Which chromosomes are represented? How many SNPs are on each?

<br>

**Part 0 Report**

In Part 0, we imported annotation data (`scanAnnot` & `snpAnnot`) and array data (genotyping data and intensity data, including qxy and bl) into the work space and then combined/packed them for downstream QC processes. The combined data include `genoData` (genotype data), `qxyData`, and `blData` (intensity data).

Q1: In detail, we found both `scanID` and `subjectID` in Scan Annotation data. They are both provided because `subjectID` refers to a specific participant, while `scanID` refers to a specific genotyping run. It is highly possible for a subject/participant to be sequenced/genotyped for more than once, for intended duplication purpose or for different tissue types, etc. Thus, both ID should be provided. 

Q2: 13 families were included in the study, and the number of samples in each family is summarized in table `samples_per_fam`

Q3: Among all samples/scans, 35 were from females, and 42 were from males.

Q4: 49 samples were from CEU, and 28 samples were from YRI

Q5: There were 77 samples, which came from 43 people.

Q6: There were 3300 SNPs with unique `snpID` (and `rsID`)

Q7: Chromosomes included in this study:
chromosome  number_of_SNPs
21	        1000			
22	        1000			
23(X)	    1000			
24(Y)       100			
25(XY)      100			
26(MT)      100	

```{r part0_report}
# Your code goes here
## Q1
pData(scanAnnot) %>% head()

## Q2
pData(scanAnnot) %>% select(family) %>% unique() %>% nrow()

samples_per_fam = 
  pData(scanAnnot) %>% 
  select(family, scanID) %>% 
  group_by(family) %>%
  count()
samples_per_fam

## Q3
pData(scanAnnot) %>% select(sex, scanID) %>%
  group_by(sex) %>%
  count()

## Q4
pData(scanAnnot) %>% select(race, scanID) %>%
  group_by(race) %>%
  count()

## Q5
pData(scanAnnot) %>% select(scanID) %>% unique() %>% nrow()
pData(scanAnnot) %>% select(subjectID) %>% unique() %>% nrow()

## Q6
pData(snpAnnot) %>% select(snpID) %>% unique() %>% nrow()
# pData(snpAnnot) %>% select(rsID) %>% unique() %>% nrow()

## Q7
pData(snpAnnot) %>% select(chromosome, snpID) %>% group_by(chromosome) %>% count()

```

<hr>

<br>

## Part 1 - Missing Call Rate for Samples and SNPs

The basic `{GWASTools}` functions for missingness are `missingGenotypeBySnpSex()` and `missingGenotypeByScanChrom()`. 

- `missingGenotypeBySnpSex()` returns a list of three objects: `missing.counts`, `scans.per.sex`, and `missing.fraction`. Read the help file for this function so that you understand what information is contained in these and how the Y chromosome is treated by sex (where sex is as defined in the scan annotation). 

- Similarly, `missingGenotypeByScanChrom()` returns `missing.counts`, `snps.per.chr`, and `missing.fraction`.


There are four basic missingness calculations to be done, in the following order.

1. Calculate `missing.n1` = fraction of **genotype calls** missing over all samples (except that annotated âfemaleâ individuals are excluded for Y chr SNPs)

2. Calculate `missing.e1` = missing call rate **per sample** over all SNPs (excluding SNPs with all calls missing)

3. Calculate `missing.n2` = call rate **per SNP** over all samples whose `missing.e1` is less than `0.05`

4. Calculate `missing.e2` = missing call rate **per sample** over all SNPs with `missing.n2` values less than `0.05`

We'll want to store the missingness information in the annotation data frames as we proceed.

<br>

### Round 1

Here's how to calculate and store `missing.n1`.

```{r missing.n1, eval=TRUE}

### Using missingGenotypeBySnpSex to calculate missing.n1 ###

#   First look at some of the results
miss <- missingGenotypeBySnpSex(genoData)
names(miss)

head(miss$missing.counts) #all snps
miss$scans.per.sex
head(miss$missing.fraction)

#   We should make sure the snpIDs are in the same order in the annotation and
#   in the missingness report (miss$missing.fraction); they are

allequal(snpAnnot$snpID, as.numeric(names(miss$missing.fraction)))

#   Then go ahead and add missing.n1 as a new annotation data column, and update
#   the metadata
pData(snpAnnot)$missing.n1 <- miss$missing.fraction
varMetadata(snpAnnot)["missing.n1", "labelDescription"] <- 
  paste("fraction of genotype calls missing over all samples, except that females are excluded for Y chr SNPs")

## checks
getVariableNames(snpAnnot)
getMetadata(snpAnnot) %>% tail(n=2)

### Explore the missing call rate per probes a little more

#   Look at the distribution of missingness for all the probes
hist(
  pData(snpAnnot)$missing.n1,
  ylim = c(0, 100),
  xlab = "SNP missing call rate",
  main = "Missing Call Rate for All Probes"
)

#   How many SNPs are missing a genotype for every single sample? Apparently
#   there are 151 such SNPs

sum( pData(snpAnnot)$missing.n1 == 1 )

#   Store a vector containing the snpIDs of all the SNPs with missingness of
#   100%

snpexcl <- pData(snpAnnot)$snpID[snpAnnot$missing.n1 == 1]

```

<br>

Now we calculate and store `missing.e1`. The steps are described in the comments below.

```{r missing.e1, eval=TRUE}

### Using missingGenotypeByScanChrom to calculate missing.e1

#   Apply missingGenotypeByScanChrom to genoData, using the snp.exclude option
#   to exclude these SNPs (why does it make sense to exclude those SNPs?)

miss <- missingGenotypeByScanChrom(genoData, snp.exclude = snpexcl)

#   Make sure the order of the scanIDs in the output from
#   missingGenotypeByScanChrom is the same as the order of the scanIDs in the
#   annotation data frame

allequal(names(miss$missing.fraction) %>% as.numeric(), 
         pData(scanAnnot)$scanID)

#   Make a new column in scanAnnot called missing.e1 and store the per-scan
#   missingness from missingGenotypeByScanChrom there

pData(scanAnnot)$missing.e1 <- miss$missing.fraction

#   Update the scanAnnot metadata - using setter functions

varMetadata(scanAnnot)["missing.e1", "labelDescription"] =
  "fraction of genotype calls missing over all snps with missing.n1<1 except that Y chr SNPs are excluded for females"


## check
getVariableNames(scanAnnot)
getMetadata(scanAnnot) %>% tail(n=2)


# We can check summary statistics and make a histogram, too

summary(scanAnnot$missing.e1)
hist(
  scanAnnot$missing.e1,
  xlab = "Fraction of sample-missingness across all probes",
  main = "Histogram of Sample Missing Call Rate for All Samples"
)

```

<br>

### Round 2

Now, supply your code to calculate and store `missing.n2`. The steps you should follow are described in the comments below. 

```{r missing.n2, eval=TRUE}

### Now that missing.n1 and missing.e1 have been calculated, we can calculate missing.n2

#   Recall that missing.n2 = call rate per SNP over all samples whose missing.e1
#   is less than 0.05.

#       Since no sample had missing.e1 > 0.05 in this dataset, we don't actually
#       have to exclude any samples.

#   However, let's proceed as if there were some samples with missing.e1 > 0.05.

# Make a vector of the scanIDs for the samples with high missing.e1.
scan_exclude = 
  pData(scanAnnot) %>% 
  filter(missing.e1 > 0.05) %>%
  select(scanID) %>% 
  pull()

length(scan_exclude)

#   Apply the missingGenotypeBySnpSex function again, using the scan.exclude
#   argument.
miss = missingGenotypeBySnpSex(genoData = genoData, scan.exclude = scan_exclude)

#   Store missing.n2 as a new column in snpAnnot.
## same sequence
all.equal( names(miss$missing.fraction) %>% as.numeric(), 
           pData(snpAnnot)$snpID ) #TRUE

## assign to annot data
pData(snpAnnot)$missing.n2 = miss$missing.fraction

#   Update the metadata for snpAnnot!
varMetadata(snpAnnot)["missing.n2", "labelDescription"] = "SNP-level missingness, in samples with sample-missing rate (missing.e1) <= 5%"

#   The labelDescription for missing.n2 should be "fraction of genotype calls
#   missing over all samples with missing.e1 < 0.05 except that females are
#   excluded for Y chr SNPs"

## checks
getVariableNames(snpAnnot)
getMetadata(snpAnnot) %>% tail(n=2)

```

<br>

Write code to calculate and store `missing.e2`. The steps you should follow are described in the comments below.

```{r missing.e2, eval=TRUE}

### Last, we calculate missing.e2

#   Recall missing.e2 = missing call rate per sample over all SNPs with
#   missing.n2 values less than 0.05

#   Store a vector with the snpIDs of all probes with missing.n2 >= 0.05
snp_exclude_r2 = 
  pData(snpAnnot) %>%
  filter(missing.n2 >= 0.05) %>%
  pull(snpID) #snps with missing>5%

length(snp_exclude_r2)

#   Apply missingGenotypeByScanChrom to genoData again, using the snp.exclude
#   argument to exclude the SNPs with missing.n2 >= 0.05 (why do we do this?)

miss = missingGenotypeByScanChrom(genoData, snp.exclude = snp_exclude_r2)
  ## We do this to ensure that the bad snps are removed prior to removing bad samples, which has a larger effect on downstream analysis.


#   Make a new column in scanAnnot called missing.e2 to store the missingness
#   per-scan you just calculated
all.equal( names(miss$missing.fraction) %>% as.numeric(), 
           pData(scanAnnot)$scanID ) #same sequence

pData(scanAnnot)$missing.e2 = miss$missing.fraction

#   Update the scanAnnot metadata
varMetadata(scanAnnot)["missing.e2","labelDescription"] = "Sample-missingness across all snps with missing.n2 < 0.05, except that Y chr SNPs are excluded for females"

## checks
getVariableNames(scanAnnot)
getMetadata(scanAnnot) %>% tail(n=2)

```

## Part 1 - Report

Summarize the filtering you've accomplished at this step. Include the following in your answer the following questions.

* (DONE) (First, make sure you've filled in the calculations of `missing.n2` and `missing.e2` in the chunks above.)

* (DONE) How many SNPs and samples were genotyped?

* (DONE) Briefly describe the purpose of doing this step in two rounds (why do we calculate both missingnesses twice?)

* (DONE) What were the median, mean, and maximum per-sample missingness (use `missing.e2`)? Make a histogram of `missing.e2`.

* (DONE) How many samples had no missing calls at all (use `missing.e2`)?

* (DONE) Are the samples generally "good"? How many should be excluded from downstream analyses?

* (DONE) How many SNPs had a 100% missing call rate (use `missing.n1`)?

* (DONE) What are the median, mean, and maximum per-SNP missingnesses (use `missing.n2`)? How many SNPs are missing no calls at all?

* (DONE) Make a histogram of `missing.n2`.

* (DONE) How many SNPs are filtered out and how many remain if you retain only SNPs with `missing.n2` < 0.05?

* (DONE) Make a histogram showing `missing.n2` for the remaining SNPs.

<br>

**Report**: We have finished 2 rounds of missingness checks. In this study, 3300 SNPs and 77 samples were genotyped. Our rationale of performing 2 rounds of missingness check is that for the first round, we try to capture the problematic SNPs (totally missed) and, after excluding them, the problematic samples with high missing rate. Based on the primarily filtered data, we can further refine the missingness calculation in the second round, which will be used in the downstream pipeline.

The median, mean, and max sample-missingness were calculated to be 0.00065, 0.0018, and 0.024, respectively. The histogram for `missing.e2` is shown below, which is named as "Histogram of sample-missingness (missing.e2) across high-quality SNPs". There were 6 samples with no missing calls at all (i.e., sample-level missingness = 0). *Sample-level missing rate < 5%* were defined as generally "good", and all samples met this criteria and no samples should be excluded in the downstream analyses. 

There were 151 SNPs with 100% missing call rate. For the SNP-level missingness, we have median=0, mean=0.049, max=1. 2755 SNPs were missing no calls at all (i.e., snp-level missingness = 0). We created a histogram for `missing.n2` below, which is named "Histogram of SNP-level missingness (missing.n2) across high-quality samples". Using a filtering threshold of *SNP-level missingness < 0.05*, we kept 3095 SNPs while removing 205 SNPs. The histogram for the remaining SNPs were generated, named "Histogram of SNP-level missingness for high-quallity SNPs across high-quality samples".


```{r part1_report}
# check for missing.n2 & missing.e2
# pData(snpAnnot)$missing.n2
# pData(scanAnnot)$missing.e2

pData(snpAnnot)$snpID %>% unique() %>% length()
pData(scanAnnot)$scanID %>% unique() %>% length()

# What were the median, mean, and maximum per-sample missingness (use `missing.e2`)? Make a histogram of `missing.e2`.
summary( pData(scanAnnot)$missing.e2 ) 
hist(pData(scanAnnot)$missing.e2, 
     ylim = c(0, 100), 
     xlab = "Sample missingness",
     main = "Histogram of sample-missingness (missing.e2)\n across high-quality SNPs")

# How many samples had no missing calls at all (use `missing.e2`)?
sum( pData(scanAnnot)$missing.e2 == 0 )

# Are the samples generally "good"? How many should be excluded from downstream analyses?
sum( pData(scanAnnot)$missing.e2 >= 0.05 )

# How many SNPs had a 100% missing call rate (use `missing.n1`)?
sum( pData(snpAnnot)$missing.n1 == 1 )

# What are the median, mean, and maximum per-SNP missingnesses (use `missing.n2`)? How many SNPs are missing no calls at all?
summary( pData(snpAnnot)$missing.n2 ) #median=0, mean=0.049, max=1
sum( pData(snpAnnot)$missing.n2 == 0 )

# Make a histogram of `missing.n2`
hist(pData(snpAnnot)$missing.n2,
     xlab = "SNP-level missingness",
     main = "Histogram of SNP-level missingness (missing.n2)\n across high-quality samples")

# How many SNPs are filtered out and how many remain if you retain only SNPs with `missing.n2` < 0.05?
## kept
sum( pData(snpAnnot)$missing.n2 < 0.05 ) #3095 kept
sum( pData(snpAnnot)$missing.n2 >= 0.05 ) #205 lost
# length(snp_exclude_r2)

# Make a histogram showing `missing.n2` for the remaining SNPs.
pData(snpAnnot) %>%
  filter( !(snpID %in% snp_exclude_r2) ) %>%
  # summarize(tmp=max(missing.n2)) #check
  pull(missing.n2) %>%
  hist(., xlab="SNP-level missingness",
       main="Histogram of SNP-level missingness\n for high-quallity SNPs across high-quality samples")

```

<hr>

<br>

## Part 2 - Inferred vs. Reported Sex and Relatedness

To investigate discrepancies in inferred vs. reported sex (and, possibly, sex chromosome aneuploidies), we will produce four plots that summarize each scan's heterozygosity and intensity for the sex chromosomes:

1. Mean Y chromosome vs. mean X chromosome intensity

2. Mean X chromosome heterozygosity vs. mean X chromosome intensity

3. Mean Y chromosome intensity vs. mean X chromosome heterozygosity

4. Mean X chromosome heterozygosity vs. autosomal heterozygosity

Recall that the intensity data was read in earlier as `qxyData`. Before making our graphs, we'll need to calculate the variables we want to plot. The basic function we'll use to do this is `meanIntensityByScanChrom()`, which will return a list of matrices. Read the help file of this function so that you understand the output. Heterozygosity is calculated with `hetByScanChrom()`.

```{r sex_check, eval=TRUE}

#   Look at the structure of the IntensityData object
qxyData
qxyData@data

#   For each probe, there's a numerical ID, chromosome, position, rsID

#   The intensities (stored as variables called X and Y) are each essentially
#   3300Ã77 matrices (an X and Y intensity for each scan for every single probe)

#   (Don't confuse the *intensity variable names* _X_ and _Y_ in the IntensityData
#   object with the X and Y *chromosomes*!)

#   Apply the meanIntensityByScanChrom function to get the intensity averages.
#   (We're not going to use all of the output from this function)
inten.by.chrom <- meanIntensityByScanChrom(qxyData)

#   Extract the matrix containing the mean intensity for each chromosome for each scan
names(inten.by.chrom)
mninten <- inten.by.chrom$mean.intensity

#   The matrix is 77x6 since there are 77 samples and 6 chromosomes represented in the dataset
dim(mninten)
head(mninten)


#   We also need to calculate the X chromosome and autosome heterozygosities for
#   each sample before we can plot them

#   Apply hetByScanChrom to genoData (we need actual genotypes to calculate the
#   heterozygosity)
het.results <- hetByScanChrom(genoData)
    #   The function calculates eachs scan's heterozygosity for each chromosome, and
    #   also for the autosomes as a whole

#   We want to add X and autosome heterozygosity as new columns in scanAnnot
#   Make sure the scanIDs are in the right order first! (they are)
allequal(scanAnnot$scanID, rownames(het.results))

#   Extract the autosomal and X heterozygosity and store them in scanAnnot
scanAnnot$het.A <- het.results[, "A"]
scanAnnot$het.X <- het.results[, "X"]

#   Add appropriate metadata
varMetadata(scanAnnot)["het.A", "labelDescription"] <- "fraction of heterozygotes for autosomal SNPs"
varMetadata(scanAnnot)["het.X", "labelDescription"] <- "fraction of heterozygotes for X chromosome SNPs"


#   Before making the plots, there are a few things to do: We want to color the plotted points by annotated sex

#   But first, make sure that the order of the scanIDs (and hence the annotated sexes) matches the order of the scanIDs in the data we'll plot
allequal(scanAnnot$scanID, rownames(mninten))

#   Now we assign each sex a color (male=blue, female=red) - Store the colors in a vector
xcol <- rep(NA, nrow(scanAnnot))
xcol[scanAnnot$sex == "M"] <- "blue"
xcol[scanAnnot$sex == "F"] <- "red"

#   We also want to count the number of SNPs getting included on the X and Y chromosomes (which are coded as 23 and 25 in snpAnnot)
nx <- sum(snpAnnot$chromosome == 23)
ny <- sum(snpAnnot$chromosome == 25)


#### Now make the plots - Setup parameters for each plot

# All intensities
x1 <- mninten[, "X"]
y1 <- mninten[, "Y"]
main1 <- "Mean X vs \nMean Y Chromosome Intensity"

# Het on X vs X intensity
x2 <- mninten[, "X"]
y2 <- scanAnnot$het.X
main2 <- "Mean X Chromosome Intensity vs Mean X Chromosome Heterozygosity"

# Het on X vs Y intensity
y3 <- mninten[, "Y"]
x3 <- scanAnnot$het.X
main3 <- "MeanX Chromosome Heterozygosity vs Mean Y Chromosome Intensity"

# X vs A het
x4 <- scanAnnot$het.A[scanAnnot$sex == "F"]
y4 <- scanAnnot$het.X[scanAnnot$sex == "F"]
main4 <- "Mean Autosomal Heterozygosity vs Mean X Chromosome Heterozygosity"


# Make labels for axes/legends
cols <- c("blue", "red")
mf <- c("male", "female")
xintenlab <- paste("X intensity (n=", nx, ")", sep = "")
yintenlab <- paste("Y intensity (n=", ny, ")", sep = "")


#### Make the 4 plots and add a legend
par(mfrow = c(2, 2))
plot(
  x1,
  y1,
  xlab = xintenlab,
  ylab = yintenlab,
  main = main1,
  col = xcol,
  cex.main = 0.8
);legend("bottomleft",
       mf,
       col = cols,
       pch = c(1, 1),
       cex = 0.5)
plot(
  x2,
  y2,
  col = xcol,
  xlab = xintenlab,
  ylab = "X heterozygosity",
  main = main2,
  cex.main = 0.8
)
plot(
  x3,
  y3,
  col = xcol,
  ylab = yintenlab,
  xlab = "X heterozygosity",
  main = main3,
  cex.main = 0.8
)
plot(
  x4,
  y4,
  col = "red",
  xlab = "Autosomal heterozygosity",
  ylab = "X heterozygosity",
  main = main4,
  cex.main = 0.8
)
par(mfrow = c(1, 1))

```


## Part 2 - Report (Sex Check)

* (DONE) Describe any anomalies you see in the 4 plots above.

* (DONE) Figure out the scanIDs of any scans that look like outliers or possible instances of mislabeled sex. Include these IDs in your report and describe why they appear to be mislabeled.

* (DONE) For the purposes of this assignment we will ASSUME that some scans have just had their sexes mislabeled. (In "real life", we would not just assume this, and we might instead flag these scans for removal from some downstream steps/analyses.)

* (DONE) Manually change the sex annotation for these scans in scanAnnot to "remove" the discrepancy. (Manually changing your data is risky and not generally recommended. Be careful!). 
    * (DONE) In your report, state exactly what changes you made. Add a new column to scanAnnot indicating this, too (add appropriate metadata). Does anything in the pedigree structure make you more confident that this "fix" is correct? (Are these samples labeled as mothers or fathers?)

* (DONE) Remake the 4 plots above, using the "corrected" data (nothing should appear mislabeled now for this dataset).

* (DONE) How might you follow up on this "in real life"?

<br>

**Report**:  (side-note:`scanAnnot`, `mninten`)

From the chrY vs chrX intensity plot, we found 2 scans (scanID=325,326) whose reported sex was female, but they showed strong Y intensity but lower X intensity, suggesting a mismatch here and that their inferred sex is male. 

From the chrX het vs chrX intensity plot, we found that in the males cluster, there were reported females (scanID=325,326) showing low X intensity and X het=0, which should be inferred as a male. The scanID matches with plot 1.

From the chrY intensity vs chrX het plot, we found that in the males cluster, there were reported females (scanID=325,326) showing het.x=0 and with high Y intensity, which should be inferred as males. (same information as previous two plots)

From the chrX het vs autosomal het plot, we found outliers & reported females who has 0 chrX heterozygosity (scanID=325,326), which should be inferred as males. Since autosomal heterozygosity should be a spectrum, I am not very worried about the outliers on the x-axis, but to *keep a note the two reported females scanID=338,339*.

- [Conclusion] wrong reported sex: scanID = 325, 326 (should be males)

We further manually corrected the mislabeled sex for scanID=325,326 in the scanAnnot by the code: `pData(scanAnnot)[which( pData(scanAnnot)$scanID %in% c(325, 326) ),]$sex = rep(unique(pData(scanAnnot)$sex)[2], 2)`, which is to change the sex from "F" to "M". We further added a new column `changed_to_QC_inferredSex` (only 325, 326 is TRUE) to scanAnnot, indicating this change. From the pedigree structure of family 1408, the subjectID (200094287) associated with the scanIDs is labeled as **father** of the family, further indicating that our fix should be correct.

After remaking the 4 plots using data with updated sex, there are no more mismatches observed. 

In real life, we would further check the BAF and LRR plots to confirm if the copy number or intensity of the scans' sex chromosomes are expected. Also, we can check on the plate, batch, and other technical information logged in the data to see if there are other possibilities contributing to this mismatch. 


```{r part2_report_sex_check}
# Plot 1
ls_plt1_reportedSex = 
    pData(scanAnnot) %>%
    select(scanID, sex) %>%
    filter(sex=="F") %>% #find those reported as females
    pull(scanID)

ls_plt1_reportedSex[
    #find those inferred as males -> find the overlap
    ls_plt1_reportedSex %in% rownames(mninten)[mninten[,"Y"] > 0.5] 
]

# Plot 2
pData(scanAnnot) %>%
    select(scanID, sex, het.X) %>%
    filter(sex=="F" & het.X < 0.15) %>% #find those reported as females && low het.x
    pull(scanID)

c(325,326) %in% rownames(mninten)[mninten[,"X"]<0.9] #confirmed

# Plot 3 - same info as before
c(325,326) %in% rownames(mninten)[mninten[,"Y"] > 0.5]

# Plot 4 - same info as before
pData(scanAnnot) %>%
    select(scanID, sex, het.A) %>%
    filter(sex=="F" & het.A < 0.282) %>% #find those reported as females && low het.A
    pull(scanID)
```


Manually change the mislabeled sex

```{r}
# 1. Update sex
pData(scanAnnot)[which( pData(scanAnnot)$scanID %in% c(325, 326) ),]$sex =
    rep(unique(pData(scanAnnot)$sex)[2], 2)
## check
pData(scanAnnot)[which( pData(scanAnnot)$scanID %in% c(325, 326) ),]$sex


# 2. Add a new column to indicate the change
pData(scanAnnot) = 
    pData(scanAnnot) %>%
    mutate(changed_to_QC_inferredSex = 
               if_else(condition=scanID %in% c(325, 326), 
                       true=TRUE, false=FALSE) 
           ) #%>% filter(changed_to_QC_inferredSex)
## checks
pData(scanAnnot) %>% filter(changed_to_QC_inferredSex)


# 3. Modify the metaData
varMetadata(scanAnnot)["changed_to_QC_inferredSex","labelDescription"] = 
    "Logical vector; TRUE if we manually changed the scanID's `sex` to the opposite, based on the results of QC step 'Reported Sex vs Inferred Sex' "
## checks
varMetadata(scanAnnot) %>% tail(n=2)
getVariableNames(scanAnnot)


# 4. check pedigree
pData(scanAnnot) %>% filter(family==1408)

```

Remake the 4 plots above, using the "corrected" data 

```{r}
allequal(scanAnnot$scanID, rownames(mninten))

# Reassign sex
xcol <- rep(NA, nrow(scanAnnot))
xcol[scanAnnot$sex == "M"] <- "blue"
xcol[scanAnnot$sex == "F"] <- "red"

#   We also want to count the number of SNPs getting included on the X and Y chromosomes (which are coded as 23 and 25 in snpAnnot)
nx <- sum(snpAnnot$chromosome == 23)
ny <- sum(snpAnnot$chromosome == 25)


#### Now make the plots - Setup parameters for each plot

# All intensities
x1 <- mninten[, "X"]
y1 <- mninten[, "Y"]
main1 <- "[updated] Mean X vs \nMean Y Chromosome Intensity"

# Het on X vs X intensity
x2 <- mninten[, "X"]
y2 <- scanAnnot$het.X
main2 <- "[updated] Mean X Chromosome Intensity vs Mean X Chromosome Heterozygosity"

# Het on X vs Y intensity
y3 <- mninten[, "Y"]
x3 <- scanAnnot$het.X
main3 <- "[updated] MeanX Chromosome Heterozygosity vs Mean Y Chromosome Intensity"

# X vs A het
x4 <- scanAnnot$het.A[scanAnnot$sex == "F"]
y4 <- scanAnnot$het.X[scanAnnot$sex == "F"]
main4 <- "[updated] Mean Autosomal Heterozygosity vs Mean X Chromosome Heterozygosity"


# Make labels for axes/legends
cols <- c("blue", "red")
mf <- c("male", "female")
xintenlab <- paste("X intensity (n=", nx, ")", sep = "")
yintenlab <- paste("Y intensity (n=", ny, ")", sep = "")


#### Make the 4 plots and add a legend
par(mfrow = c(2, 2))
plot(
  x1,
  y1,
  xlab = xintenlab,
  ylab = yintenlab,
  main = main1,
  col = xcol,
  cex.main = 0.8
);legend("bottomleft",
       mf,
       col = cols,
       pch = c(1, 1),
       cex = 0.5)
plot(
  x2,
  y2,
  col = xcol,
  xlab = xintenlab,
  ylab = "X heterozygosity",
  main = main2,
  cex.main = 0.8
)
plot(
  x3,
  y3,
  col = xcol,
  ylab = yintenlab,
  xlab = "X heterozygosity",
  main = main3,
  cex.main = 0.8
)
plot(
  x4,
  y4,
  col = "red",
  xlab = "Autosomal heterozygosity",
  ylab = "X heterozygosity",
  main = main4,
  cex.main = 0.8
)
par(mfrow = c(1, 1))
```

<hr>

<br>

## Part 3 - Allelic Imbalance; BAF and LRR Plots

Here we want to look at B allele frequency (BAF) and log R ratio (LRR) plots using `chromIntensityPlot()`. Ordinarily, since there are 22 to 23 chromosomes to check for every sample, you would use a script that automatically detects aberrations in BAF and LRR. For this project, we'll pretend that our pipeline has already **flagged one sample for a possible chromosomal anomaly**.

```{r baflrr, eval=TRUE}

# Recall that earlier we read the intensity data into an IntensityData object
# called blData.
class(blData) # The snp/scan annotation were attached as well.

# Suppose that chromosome 22 was flagged for scanID 286.

# Making the BAF/LRR plot is easy
#dev.off()
chromIntensityPlot(blData, scan.ids = 286, chrom.ids = 22)
par(mfrow = c(1, 1))

```

## Part 3 - Report

* (DONE) Describe the purpose of this step.

* (DONE) Show an example of a "normal" pair of BAF/LRR plots (choose any chromosome/scanID you want).

* (DONE) How would you detect trisomy 21 (i.e., describe briefly in words what the BAF/LRR plot would look like).

* (DONE) Suppose an individual had a balanced reciprocal translocation involving chromosome 2 and 4. What would you expect that individual's BAF/LRR plots would look like for those chromosomes?

* (DONE) Suppose chromosome 22 in sample 286 was the only chromosome flagged for a possible anomaly in this dataset. Looking at the plot, do you notice anything strange? Can you suggest what kind of anomaly might be showing up? (There isn't any single answer that's certainly right! The purpose of this question is to check that you understand what the BAF and LRR plots "mean").

* (DONE) Finally, suppose your pipeline has given you a list of the exact chromosomal segments showing possibly aneuploidies/anomalies in each sample. What would you recommend doing with the genotypes in those segments? (You're not being asked to implement this here - just say what you recommend doing.)

<br>

**Report**: 

* The purpose of this step is to assess allelic imbalance: using BAF plot to check the genotype information, aneuploidy, and mosaicism based on the number of bands, and using LRR plot to check the copy number or intensity for this region of the chromosome and for this scan. 

* I created a "normal" pair of BAF/LRR plots for scan 312, chromosome 21 (may have a little bit loss of heterozygosity)

* To detect trisomy 21, we expected that the LRR will be higher than 0 (at 0.5) for the entire chromosome 21 indicating copy number = 3, and that the BAF will show 4 bands at 0, 0.33, 0.66, 1, instead of 3 bands observed in disomy.

* Given that a balanced reciprocal translocation happened, indicating just an (structural) exchange of chromosomal location without genetic content loss or increase (i.e., the copy number should not change), and without big changes in genotype (still AA, AB, BB), the BAF/LRR plots of this individual would be like *normal* for those two chromosomal regions--mean LRR being 0, and 3 bands in BAF plot.

* Looking at the plot, I can see 1) loss of heterozygosity (LOH) at 26-27Mb & 37Mb, and 2) there are something wrong at 21-22Mb, possibly contamination since there is nothing shown in the LRR but there are a couple signals in the BAF plot.

* I would check those segments manually, and remove the segments (i.e., setting those segments as not being called) in all samples if most of the samples reported this problem. For other segments that are sample-specific, we can remove the specific regions only in those samples. For all the removal, keep a record of the regions and a copy of the original data for recovery purpose. Of course, this would involve a group's discussion.


```{r part3_report}
# Show an example of a "normal" pair of BAF/LRR plots
chromIntensityPlot(blData, scan.ids = 312, chrom.ids = 21)
par(mfrow = c(1, 1))

```

<hr>
<br>

## Part 4 - Relatedness

Next, we estimate the identity-by-descent (IBD) coefficients for each pair of scans in order to describe genetic relatedness. There are various methods for doing this. We'll use the <mark>KING method</mark>, implemented in the `SNPRelate` package. The `pedigreeCheck` function will help us look for errors in the pedigree (i.e., the reported relationships) before comparing reported vs. genetic relatedness. Look at the help menu for this function to see what kinds of inconsistencies it reports on. Then `pedigreePairwiseRelatedness` will calculate the expected genetic relatedness for each pair of subjects, based on the reported pedigree structure.

```{r relatedness, eval=TRUE}

#   Close the connection to the genotypes gds file (recall that we changed the
#   sexes in the previous step, so we should "remake" genoData with the updated
#   annotation)

close(genoData)

#   Re-open the data

gds_geno <- system.file("extdata", "illumina_geno.gds", package="GWASdata")
gdsobj <- snpgdsOpen(gds_geno)
class(gdsobj)

#   Let's use the snp.id argument to include only "good" SNPs in the calculation
#   (missing.n2 < 0.05)
varMetadata(snpAnnot) #check the parameters

snps_to_include_for_kinship <- snpAnnot$snpID[snpAnnot$missing.n2 < 0.05]

#   Apply snpgdsIBDKING to calculate relatedness statistics. The IBD object
#   returned is a list containing scanIDs, snpIDs, and two relatedness matrices

ibdobj <- snpgdsIBDKING(gdsobj, snp.id = snps_to_include_for_kinship)
snpgdsClose(gdsobj)
dim(ibdobj$kinship)

#   Observe that monomorphic and non-autosomal SNPs are also being excluded by
#   default

#   Recall that the relatedness matrices are symmetric 77Ã77 matrices (the entry
#   in row i, column j is the coefficient for samples i and j)

ibdobj$kinship[1:5, 1:5]

#   Next, we use pedigreeCheck to look for problems in the pedigree (duplicates,
#   impossible relationships, and other inconsistencies)

#   The goal is to clean up the pedigree before applying the functions that will
#   determine the expected relatedness coefficients

#   First, pull out all the pedigree information from the scan annotation (77
#   scans)

#   Notice that we're using subjectID and not scanID here (recall the
#   difference)

ped <- pData(scanAnnot)[, c("family", "subjectID", "father", "mother", "sex")]
dim(ped)

#   Rename the subjectID variable
names(ped) <- c("family", "individ", "father", "mother", "sex")
head(ped)

#   pedigreeCheck has returned a list of three data frames: duplicates,
#   parent.no.individ.entry, and unknown.parent.rows

chk <- pedigreeCheck(ped)
chk

#   We'll deal with these in turn

######## 1. we remove duplicates from the pedigree ########

#   Get the data frame of duplicates from chk
dups <- chk$duplicates
head(dups)

#   Use the pedigreeDeleteDuplicates function to make a new pedigree with the duplicates removed

uni.ped <- pedigreeDeleteDuplicates(ped, dups)
dim(uni.ped)

#   Observe that uni.ped is smaller than ped

#   Now we apply pedigreeCheck again

chk <- pedigreeCheck(uni.ped)

#   Examining chk, we see that there are three types of problem

#   (Note that pedigreeCheck would have identified the mismatched sexes if we
#   had not fixed them already)

#   We deal with these in turn

#    parent.no.individ.entry
#    unknown.parent.rows
#    subfamilies.ident

chk

#   parent.no.individ.entry

#   This means the person in row 8 of uni.ped has a parent (mother) whose ID
#   (200039107) doesn't occur as an "individ" in the pedigree

#   We fix this by simply making and adding on a new row for this mother

ni <- chk$parent.no.individ.entry
ni
head(uni.ped) #check the format

parent <-
  data.frame(
    family = ni$family,
    individ = ni$parentID,
    father = 0,
    mother = 0,
    sex = "F",
    stringsAsFactors = FALSE
  )

#   Call the new pedigree ped.updated and apply pedigreeCheck again
ped.updated <- rbind(uni.ped, parent)
chk <- pedigreeCheck(ped.updated)
chk

#   unknown.parent.rows

#   This means the person in row 42 of ped.updated has one parent known and one
#   missing

up <- chk$unknown.parent.rows
up

#   Let's look at this family (family 58)

ped.updated[ped.updated$family == 58, ]

#   Apparently the mother is unknown

#   Let's make up an individ ID for this mother, enter it it as the son's
#   mother's ID, and add a row to the pedigree for her

ped.updated[42, "mother"] <- 987654321
parent <-
  data.frame(
    family = up$family,
    individ = 987654321,
    father = 0,
    mother = 0,
    sex = "F",
    stringsAsFactors = FALSE
  )

#   Call the filled-out pedigree ped.complete, and apply pedigreeCheck
ped.complete <- rbind(ped.updated, parent)
chk <- pedigreeCheck(ped.complete)
chk

#   subfamilies.ident

subf <- chk$subfamilies.ident
subf
table(subf$family)

#   This identifies subfamilies (families where not everyone is linked into the
#   same pedigree as constructed by fathers'/mothers' IDs)
ped.complete %>% filter(family==1341)
subf

#   We should make these subfamilies into new families

#   Get the individuals from subfamily 2 from each family and add on "-2" their
#   family IDs

subf.ids <- subf$individ[subf$subfamily == 2]
newfam <- ped.complete$individ %in% subf.ids
ped.complete$family[newfam] <-
  paste0(ped.complete$family[newfam],"-2")

#   Now families 1341 and 1362 have been split into 2 trios (the new families
#   are 1341-2 and 1362-2)

table(ped.complete$family)

#   pedigreeCheck now returns NULL, meaning the pedigree now has no problems
pedigreeCheck(ped.complete)



#   Now we can calculate the pairwise expected relatedness for all the subjects
#   in the completed pedigree

#   The function pedigreePairwiseRelatedness returns a list summarizing the
#   relationships

rels <- pedigreePairwiseRelatedness(ped.complete)

#   First, we can see that none of the parents are related by looking at
#   inbred.fam

length(rels$inbred.fam)

#   Next we extract relativeprs, a data frame summarizing the relationships

relprs <- rels$relativeprs

#   It contains relationship type (e.g., parent-offspring, unrelated, etc.) and
#   kinship coefficient for each pair within each family

relprs[1:5,]
table(relprs$relation)

#   We see that our pedigree is relatively simple: 30 parent-offspring pairs
#   (PO) and 15 unrelated

#   (If we had a more complex pedigree structure, we would see more types of
#   relationships listed)

### Now we want to plot of the IBD coefficient estimates, color coded by the
### expected relationships we've just calculated

#   But first we need to merge together the expected and observed genetic
#   relationship data for all the pairs of scans

#   First, get all the scanIDs/subjectIDs from scanAnnot

samp <- pData(scanAnnot)[, c("scanID", "subjectID")]

#   Make sure the order matches that in the IBD object

samp <- samp[match(ibdobj$sample.id, samp$scanID), ]

#   Rename subjecID as Individ (like in the pedigree)

names(samp) <- c("scanID", "Individ")

#   Use snpgdsIBDSelection to find all pairs of samples with kinship coefficient
ibd <- snpgdsIBDSelection(ibdobj)

#   Merge in the 
ibd <- merge(ibd, samp, by.x = "ID1", by.y = "scanID")
ibd <- merge(ibd, samp, by.x = "ID2", by.y = "scanID", suffixes = c("1", "2") )

#   Create a pair-identifier variable to enable merging ibd with relprs (i.e.,
#   merge the observed and expected genetic relationship data)

ibd$ii <- pasteSorted(ibd$Individ1, ibd$Individ2)
relprs$ii <- pasteSorted(relprs$Individ1, relprs$Individ2)

#   Merge these together

ibd <- merge(ibd, relprs[, c("ii", "relation")], all.x = TRUE)

#   Rename the "relation" column (it refers to the expected relationship based
#   on the pedigree, so call it exp.rel)

names(ibd)[names(ibd) == "relation"] <- "exp.rel"

#   For pairs of samples from the same person, set exp.rel="Dup" (duplicate)

ibd$exp.rel[ibd$Individ1 == ibd$Individ2] <- "Dup"

#   For the remaining pairs with missing exp.rel, replace the missing value with "U" (unknown)

ibd$exp.rel[is.na(ibd$exp.rel)] <- "U"
table(ibd$exp.rel, useNA = "ifany")

#   Use the ibdAssignRelatednessKing function to call the observed relationships
#   based on IBS0 and kinship values for each pair

ibd$obs.rel <- ibdAssignRelatednessKing(ibs0 = ibd$IBS0, kc = ibd$kinship)
table(ibd$obs.rel, useNA = "ifany")

# Finally, plot KC vs IBS0

# Draw horizontal thresholds for assigning relationships using kinship
# coefficients (taken from table 1 of Manichaikul (2010))

cut.dup <- 1 / (2 ^ (3 / 2))
cut.deg1 <- 1 / (2 ^ (5 / 2))
cut.deg2 <- 1 / (2 ^ (7 / 2))
cut.deg3 <- 1 / (2 ^ (9 / 2))
cols <- c(Dup = "magenta",
          PO = "cyan",
          U = "black")

plot(x = ibd$IBS0,
     y = ibd$kinship,
     col = cols[ibd$exp.rel],
     xlab = "Fraction of IBS=0 (k0)",
     ylab = "Kinship coefficient (Phi)"
);abline(h = c(cut.deg1, cut.deg2, cut.deg3, cut.dup),
         lty = 2,
         col = "gray"
);legend("topright",
        legend = names(cols),
        col = cols,
        pch = 1)

library(plotly)
ibd_plot = ibd %>% 
    ggplot(aes(x=IBS0, y=kinship, color=exp.rel)) +
        geom_point(shape = "o", size = 4, alpha=0.6,
                   #from plotly
                   aes(text = paste0("ind1/ind2: ",ii,"<br>",
                                     "IBS0: ",round(IBS0,4),"<br>",
                                     "kinship ",round(kinship,4),"<br>",
                                     "expected rel: ",exp.rel,"<br>",
                                     "observed rel: ",obs.rel,"<br>")) 
                   ) + 
        geom_hline(yintercept = c(cut.deg1, cut.deg2, cut.deg3, cut.dup), 
                    linetype = "dashed", 
                    color = "gray") + 
        scale_color_manual(name="Expected Relationship",
                           values = c("magenta","cyan","black")) +
        theme_classic() + theme(legend.position="top") + 
    #add annotation for the lines
    annotate("text", x = 0.12, y = c(cut.deg1, cut.deg2, cut.deg3, cut.dup),
            label = c("cut.deg1", "cut.deg2", "cut.deg3", "cut.dup"),
            color = "black", size = 4, vjust = -0.2)

ggplotly(ibd_plot, tooltip = "text")

#plotly ref source: https://rpubs.com/McGarveyA/ggplot2-plotly

```

From the kinship plot, we see there are some inconsistencies between the expected and observed genetic relatedness statistics. Making a table of expected vs. observed relationships can summarize this. Taking "Deg3" and "U" ("Unrelated") as synonynmous here for simplicity, we would expect all the off-diagonal entries of the table below to be 0.

What we actually see is that 16 pairs that are supposedly unrelated are actually parent-offspring pairs; and 17 pairs that are supposedly parent-offspring pairs are showing up as genetically unrelated. Note that since there are multiple scans per person, there are a lot of relationships pairs here (77 scans implies 77 * 76 / 2 = 2926 possible pairs, which is the sum of the entries in the table). Each of the 33 discrepancies is a 'dot' in the 'wrong cluster' in the IBD plot we drew.

Can we account for these discrepancies somehow? Let's try to find the pairs of individuals/families with discrepancies. 

We see below  that only 3 families are involved (families 1344, 1334, and 58). After poring over the list of discrepancies, we also see that they can be disentangled somewhat. The discrepancy involving family 58 concerns only 2 scanIDs, 355 and 356 (both in the same family), so we can tackle it first. (On the other hand, the remaining 32 discrepancies involving families 1344 and 1334 seem more complex.) It appears  the discrepancy is due to a case of non-paternity - the pedigree in scanAnnot says that 356 is 355's father, but the kinship calculation says they're genetically unrelated. Therefore we should change the family IDs to reflect that they're unrelated.

```{r relatedness2, eval=TRUE}

#   Make a table of obsereved and expected relationships for each pair of scans
ibd_recoded <- ibd
ibd_recoded$obs.rel[ibd_recoded$obs.rel == "Deg3"] <- "U" #simplify a bit
table(expected = ibd_recoded$exp.rel, 
      observed = ibd_recoded$obs.rel,
      useNA = "ifany")

### What are the pairs with discrepancies?
#   Print out all 33 rows
discrepancies <-
  ibd_recoded[!ibd_recoded$exp.rel == ibd_recoded$obs.rel, ]
discrepancies
# Note that this table includes the scanIDs of each pair involved in a discrepancy

### Which *families* are involved?
#   Get the individual scanIDs first and match them back to the family IDs
discrepancy_ids <- unlist(discrepancies[, c("ID1", "ID2")])
discrepany_fids <-
  pData(scanAnnot)$family[pData(scanAnnot)$scanID %in% discrepancy_ids]
discrepany_fids <- unique(discrepany_fids)
discrepany_fids
## only 3 families: 1344 1334   58

pData(scanAnnot) %>% filter(family == 1344)
pData(scanAnnot) %>% filter(family == 1334)


#   The discrepancy with individuals 355 and 356 from family 58 seems easiest to
#   fix first - it only involves one family
pData(scanAnnot)[pData(scanAnnot)$family == "58", ]

discrepancies[discrepancies$ID1  %in% c(355, 356) |
                discrepancies$ID2  %in% c(355, 356) ,]


#   Since 355 and 356 are actually unrelated, we should give one of them a new
#   family ID

#   Notice we use subjectID here

#   1. Set "daughter"'s father-ID to 0
pData(scanAnnot)[pData(scanAnnot)$subjectID == 200122151, "father"] <-
  "0"

#   2. Give the "dad" a new, unique family-ID
pData(scanAnnot)[pData(scanAnnot)$subjectID == 200105428, "family"] <-
  "58-2"

pData(scanAnnot)[pData(scanAnnot)$family == 58, ]
pData(scanAnnot)[pData(scanAnnot)$family == "58-2", ]

```

Now, you should account for the remaining discrepancies, which simply involve a sample swap between families 1334 and 1344. The sample swap involves just the children from two trios (each is scanned twice, and the parents are all scanned twice).

For the swapped samples, manually "fix" their family IDs, mother IDs, and father IDs in scanAnnot (i.e., swap these IDs back so that each child has the correct parental and family IDs). You only need to adjust the variables `family`, `father`, and `mother` for 4 scans from the 2 children. One of these has completed for you. **Add your code in the next chunk, where indicated.**

```{r relatedness3, eval=TRUE}

#### Reported ####
pData(scanAnnot)[pData(scanAnnot)$family == 1334, ]
# 200071490 (298,299) is the son of 200118596 (M, 321,322) & 200019634 (F, 323,324)

pData(scanAnnot)[pData(scanAnnot)$family == 1344, ]
# 200016815 (296,297) is the son of 200116780 (M, 317,318) & 200005043 (F, 319,320)

#### Genetically, which is the TRUE setting ####
discrepancies %>% filter(ID1 %in% c(296,297) & obs.rel=="PO")
# 200016815 (296,297) in family 13-4-4 is the son of 200019634 (F) & 200118596 (M) in family 13-3-4!!

discrepancies %>% filter(ID1 %in% c(298,299) & obs.rel=="PO")
# 200071490 (298,299) in fam 13-3-4 is the son of 200005043 (F) & 200116780 (M) in fam 13-4-4


#### should be sample sawp of the children! ####


#### Scan1 from Kid 1 (scan=296, subject=200016815) ####
pData(scanAnnot)[pData(scanAnnot)$scanID == 296, c("family", "father", "mother")] <-
  c(1334, 200118596, 200019634)

# Scan2 from Kid 1 (scan 297)
pData(scanAnnot)[pData(scanAnnot)$scanID == 297, c("family", "father", "mother")] <-
  c(1334, 200118596, 200019634)


#### Scan1 from Kid 2 (subject=200071490) ####
pData(scanAnnot)[pData(scanAnnot)$scanID == 298, c("family", "father", "mother")] <-
  c(1344, 200116780, 200005043)

# Scan2 from Kid 2
pData(scanAnnot)[pData(scanAnnot)$scanID == 299, c("family", "father", "mother")] <-
  c(1344, 200116780, 200005043)

pData(scanAnnot)[pData(scanAnnot)$family == 1334, ]
pData(scanAnnot)[pData(scanAnnot)$family == 1344, ]

```


Now that we've "corrected" the sample-swaps, we should make a new IBD plot to verify that observed and expected relationships now match.

```{r relatedness4, eval=TRUE}

#   Recalculate the relatedness as above
gds_geno <- system.file("extdata", "illumina_geno.gds", package = "GWASdata")
snps_to_include_for_kinship <- snpAnnot$snpID[snpAnnot$missing.n2 < 0.05]
gdsobj <- snpgdsOpen(gds_geno)
ibdobj <- snpgdsIBDKING(gdsobj, snp.id = snps_to_include_for_kinship)
snpgdsClose(gdsobj)

#   Re-draw the pedigree
ped <- pData(scanAnnot)[, c("family", "subjectID", "father", "mother", "sex")]
dim(ped)
names(ped) <- c("family", "individ", "father", "mother", "sex")
head(ped)
chk <- pedigreeCheck(ped)
chk

#   Remove duplicates, as before
dups <- chk$duplicates
head(dups)
uni.ped <- pedigreeDeleteDuplicates(ped, dups)
dim(uni.ped)
chk <- pedigreeCheck(uni.ped)
chk

#   Recall there was a person whose mother needed to be added to the pedigree
ni <- chk$parent.no.individ.entry
ni
parent <-
  data.frame(
    family = ni$family,
    individ = ni$parentID,
    father = 0,
    mother = 0,
    sex = "F",
    stringsAsFactors = FALSE
  )
ped.updated <- rbind(uni.ped, parent)
chk <- pedigreeCheck(ped.updated)
chk

#   Recall that a family had to be broken into two new sub-families
ped.complete <- ped.updated
chk <- pedigreeCheck(ped.complete)
subf <- chk$subfamilies.ident
subf
table(subf$family)
subf.ids <- subf$individ[subf$subfamily == 2]
newfam <- ped.complete$individ %in% subf.ids
ped.complete$family[newfam] <-
  paste0(ped.complete$family[newfam], "-2")
table(ped.complete$family)
chk <- pedigreeCheck(ped.complete)
chk

#   Earlier we split family 58 into two singleton families (the "father" and
#   "daughter" who weren't actually related) pedigreeCheck doesn't like
#   singletons, so we need to assign dummy parents for the original two members
#   of family 58 And these 4 dummy parents need to be added into the pedigree

onefams <- chk$one.person.fams
onefams
ped.complete[ped.complete$family %in% c("58", "58-2"), ]
ped.complete[ped.complete$family == "58",  c("father", "mother")] <-
  c("1111", "2222")
ped.complete[ped.complete$family == "58-2", c("father", "mother")] <-
  c("3333", "4444")

# add to pedegree
parents <- data.frame(
  family = c("58",    "58",   "58-2", "58-2"),
  individ = c("1111", "2222", "3333", "4444"),
  father = c(0, 0,             0, 0),
  mother = c(0, 0,             0, 0),
  sex = c("M", "F",           "M", "F"),
  stringsAsFactors = FALSE
)

#   Complete the final pedigree, and now pedigreeCheck is happy (it returns NULL)
ped.final <- rbind(ped.complete, parents)
pedigreeCheck(ped.final)

# Recalculate expected relationships in order to make a new plot, as above
ped.complete <- ped.final
rels <- pedigreePairwiseRelatedness(ped.final)
length(rels$inbred.fam)
relprs <- rels$relativeprs
relprs[1:5, ]
table(relprs$relation)

# create/clean observed relatedness dataframe
samp <- pData(scanAnnot)[, c("scanID", "subjectID")]
samp <- samp[match(ibdobj$sample.id, samp$scanID), ]
names(samp) <- c("scanID", "Individ")

ibd <- snpgdsIBDSelection(ibdobj)
ibd <- merge(ibd, samp, by.x = "ID1", by.y = "scanID")
ibd <-
  merge(
    ibd,
    samp,
    by.x = "ID2",
    by.y = "scanID",
    suffixes = c("1", "2")
  )
ibd$ii <- pasteSorted(ibd$Individ1, ibd$Individ2)
relprs$ii <- pasteSorted(relprs$Individ1, relprs$Individ2)

# Merge observed & expected relatedness
ibd <- merge(ibd, relprs[, c("ii", "relation")], all.x = TRUE)
names(ibd)[names(ibd) == "relation"] <- "exp.rel"

ibd$exp.rel[ibd$Individ1 == ibd$Individ2] <- "Dup"
ibd$exp.rel[is.na(ibd$exp.rel)] <- "U"
table(ibd$exp.rel, useNA = "ifany")

#   Use the ibdAssignRelatednessKing function to call the observed relationships
#   based on IBS0 and kinship values for each pair
ibd$obs.rel <- ibdAssignRelatednessKing(ibd$IBS0, ibd$kinship)
table(ibd$obs.rel, useNA = "ifany")

#   Observe that now the observed and expected relationships match (if we take
#   Deg3 and Unrelated as synonymous)
table(ibd$exp.rel, ibd$obs.rel)

#   Finally, plot KC vs IBS0

#   Draw horizontal hresholds for assigning relationships using kinship
#   coefficients (taken from table 1 of Manichaikul (2010))

#   Now none of  the dots appear to be in the "wrong" clusters

cut.dup <- 1 / (2 ^ (3 / 2))
cut.deg1 <- 1 / (2 ^ (5 / 2))
cut.deg2 <- 1 / (2 ^ (7 / 2))
cut.deg3 <- 1 / (2 ^ (9 / 2))
cols <- c(Dup = "magenta",
          PO = "cyan",
          U = "black")
plot(ibd$IBS0,
     ibd$kinship,
     col = cols[ibd$exp.rel],
     xlab = "Fraction of IBS=0",
     ylab = "Kinship coefficient")
abline(
  h = c(cut.deg1, cut.deg2, cut.deg3, cut.dup),
  lty = 2,
  col = "gray"
)
legend("topright",
       legend = names(cols),
       col = cols,
       pch = 1)


# similarly, using interactive plotting
library(plotly)
ibd_plot = ibd %>% 
    ggplot(aes(x=IBS0, y=kinship, color=factor(exp.rel)) ) +
        geom_point(shape = "o", size = 4, alpha=0.6,
                   #from plotly
                   aes(text = paste0("ind1/ind2: ",ii,"<br>",
                                     "IBS0: ",round(IBS0,4),"<br>",
                                     "kinship ",round(kinship,4),"<br>",
                                     "expected rel: ",exp.rel,"<br>",
                                     "observed rel: ",obs.rel,"<br>")) 
                   ) + 
        geom_hline(yintercept = c(cut.deg1, cut.deg2, cut.deg3, cut.dup), 
                    linetype = "dashed", 
                    color = "gray") + 
        scale_color_manual(name="Expected Relationship",
                           values = c("magenta","cyan","black")) +
        theme_classic() + theme(legend.position="top") + 
    #add annotation for the lines
    annotate("text", x = 0.12, y = c(cut.deg1, cut.deg2, cut.deg3, cut.dup),
            label = c("cut.deg1", "cut.deg2", "cut.deg3", "cut.dup"),
            color = "black", size = 4, vjust = -0.2)

ggplotly(ibd_plot, tooltip = "text")

```

## Part 4 - Report (Relatedness)

* Summarize the pedigree structures you observe in the data.

    - Basically, before fixing the data, the reported pedigree showed 30 parent-offspring pairs (PO) and 15 unrelated pairs. For scan-wide pairs, the reported pedigree indicates  
    ```
    Dup   PO    U
    34    91 2801
    ```
    and the genetic relatedness indicates, indicating that there are some mismatch between PO and U pairs, which is further demonstrated through the kinship vs IBS0 plot. In detail, 16 pairs that are reported to be unrelated are PO pairs, and, at the same time, there were 17 pairs that are reported to be PO pairs were genetically unrelated:
    ```
    Deg3  Dup   PO    U 
    64    34    90 2738 
    ```

* Describe what discrepancies you observe in the initial kinship vs IBS0 plot.

    - We can clearly see that some of the Black dots (unrelated scan pairs) were in the blue dots data cloud (PO pairs), and vice-versa, meaning that some of the parent-offspring individuals are actually unrelated, and some of the unrelated pairs are actually parent-offspring! We did not observe anything wrong with the duplicates. 


* Explain exactly the kinds of swaps/discrepancies that were found, which IDs were involved, and exactly how you "fixed" them.

    - We observed two kinds of discrepancies: 
        1. the first kind: an daughter-father relationship (family ID  = 58) is reported. However, genetically, they (355 and 356) are unrelated. 
            - How to fix: we "remove" the relationship by setting the daughter's father-ID to 0, and assign a new family to father ("58-2")
        
        2. the second kind: a sample-swap of the children's scans. Specifically, it is reported that: subject 200071490 (298,299) is the son of 200118596 (M, 321,322) & 200019634 (F, 323,324); subject 200016815 (296,297) is the son of 200116780 (M, 317,318) & 200005043 (F, 319,320)
            
            - However, genetically, which is the TRUE setting, subject 200071490 (298,299) in fam 1334 is the son of 200005043 (F) & 200116780 (M) in fam 1344; subject 200016815 (296,297) in family 1344 is the son of 200019634 (F) & 200118596 (M) in family 1334!!
            - This is clearly a sample sawp of the children.
            
            - How to fix: We fix the pedigree/scanAnnot data by reassigning them to the corresponding genetically matched families. 


* How would you recommend following up on these discrepancies "in real life" (instead of just assuming we know what happened and manually changing the data, which is a *bad idea*)?

    - In the real life, we should check with the technician/researcher who have performed the genotyping, or we can take a look at the pictures or records of the sample information to ensure that this is truly a sample swap instead of other issues. If we cannot be sure, we should remove the children scans to be safe. 


* Add a column to scanAnnot called "relationship.changes", which briefly summarizes these "fixes" (add metadata for the column, too).

```{r part3_report_relatedness}

#   <Your code goes here>
pData(scanAnnot)[pData(scanAnnot)$family == 58, ] #355, fam58
pData(scanAnnot)[pData(scanAnnot)$family == "58-2", ] #356, fam58

pData(scanAnnot)[pData(scanAnnot)$family == 1334, ] #298,299
pData(scanAnnot)[pData(scanAnnot)$family == 1344, ] #296,297

# mutate a new column in pData
pData(scanAnnot) = 
    pData(scanAnnot) %>% mutate(
    relationship.changes = if_else( scanID %in% c(355,356,298,299,296,297), 
                                    true=TRUE, false=FALSE) ) 

pData(scanAnnot) %>% filter( scanID %in% c(355,356,298,299,296,297,210) )

# modify the Metadata
varMetadata(scanAnnot)["relationship.changes", "labelDescription"] = "Logical vector; TRUE if we manually changed the pedigree/scanAnnot data when the reported and genetic relatedness diagree with each other (changed to follow the genetic relatedness); FALSE if we did not change anything."

varMetadata(scanAnnot)
```

## Part 5 - Principal component analysis (PCA) and population substructure

Here you'll be introduced to performing PCA to uncover population substructure.

```{r pca, eval=TRUE}

#   For input when we calculate PCA, we want to exclude SNPs from a few
#   problematic loci

#   Including SNPs from 2q21 (LCT), HLA, 8p23, and 17q21.31 can result PCs that
#   are highly correlated with these SNPs, which is undesirable

#   GWASTools supplies the positions of these loci in the relevant genome build
#   in a data frame called pcaSnpFilters.hg18

#   (Note that these loci are on chromosomes 2, 6, 8, and 17, which aren't
#   included in our genotyping data; we'll proceed in this example as if we had
#   genome-wide SNPs)

filt <- get(data(pcaSnpFilters.hg18))

#   Next we pull out the chromosomes, positions, and IDs of the SNPs in our
#   dataset

chrom <- getChromosome(snpAnnot)
pos <- getPosition(snpAnnot)
snpID <- getSnpID(snpAnnot)
snp.filt <- rep(TRUE, length(snpID))

#   We loop over the 4 regions to be excluded and identify which of our SNPs lie
#   with the endpoints of each

for (f in 1:nrow(filt)) {
  snp.filt[chrom == filt$chrom[f] &
             filt$start.base[f] < pos & pos < filt$end.base[f]] <- FALSE
}

#   Make a vector called snp.sel containing the snpIDs of SNPs not in the
#   problematic regions; these are the SNPs we'll retain for PCA

snp.sel <- snpID[snp.filt]
length(snp.sel)

#   (None of our 3300 SNPs get filtered out in this step, since they're not on
#   chromosomes 2, 6, 8, or 17)


### We also want to filter out some samples before running PCA

### Specifically, we shouldn't include duplicates (for subjects with multiple
### samples, we'll just pick one sample)

#   We'll re-order scanAnnot by missing.e1 so duplicate subjectIDs with a higher
#   missing rate are marked as duplicates

#   It's important that scanAnnot stays in the same order when we're done


#   Before changing the order, verify that scanAnnot is ordered by increasing
#   scanID (it is)
allequal(scanAnnot$scanID, sort(scanAnnot$scanID))

#   Now re-order (lowest missing is the first -> wont be marked as duplicated) so that duplicate subjectIDs with a higher missing rate are marked as duplicates
scanAnnot <- scanAnnot[order(scanAnnot$subjectID, scanAnnot$missing.e1), ]

#   Add a new column called "duplicated" indicating who the duplicates are
scanAnnot$duplicated <- duplicated(scanAnnot$subjectID)
table(scanAnnot$duplicated, useNA = "ifany")

#   Put scanAnnot back in scanID order; this is very important!
scanAnnot <- scanAnnot[order(scanAnnot$scanID), ]
allequal(scanAnnot$scanID, sort(scanAnnot$scanID))

### tidyverse version
# scanAnnot_test <- scanAnnot
# pData(scanAnnot_test) = 
#     pData(scanAnnot_test) %>% 
#     arrange(subjectID, missing.e1) %>% 
#     mutate(duplicated=duplicated(subjectID)) %>% # only lowest missing were kept (higher missing + duplicates were removed)
#     arrange(scanID) #reorder it back to the scanID ascending (same as input sequence)
# all(pData(scanAnnot_test) == pData(scanAnnot), na.rm=TRUE)


#   Update the metadata
varMetadata(scanAnnot)["duplicated", "labelDescription"] <-
  "TRUE for duplicate scan with higher missing.e1"

#   Now make a vector of the scanIDs, leaving out the duplicates with higher
#   missingness (43 remain)
sample.sel <- scanAnnot$scanID[!scanAnnot$duplicated]
length(sample.sel)

#   Note that in some applications you would only want to include unrelated
#   subjects when calculating PCs

#   In this exploratory example, we'll include parents and their children
#   instead of restricting ourselves to unrelated "founders""



### Now we can perform LD pruning, where independent SNPs are chosen using a
### "sliding window" along the chromosomes

### Re-open the genotypes (after making sure the previous connection is closed)

#close(genoData)
showfile.gds(closeall = T)
gdsobj <- snpgdsOpen(genofile)

### Use the snpgdsLDpruning function

#   Â· sample.id/snp.id are used to retain only the samples/SNPs we picked out
#     above
#   Â· only autosomal SNPs are used
#   Â· a MAF threshold of 5% is applied
#   Â· the maximum window size we use is 1 megabase
#   Â· the LD threshold is set

#   Read the Details section of the help page for snpgdsLDpruning to understand
#   how the pruning algorithm works

snpset <- snpgdsLDpruning(
  gdsobj,
  sample.id = sample.sel,
  snp.id = snp.sel,
  autosome.only = TRUE,
  maf = 0.05,
  missing.rate = 0.05,
  method = "corr",
  slide.max.bp = 10e6, #10Mb
  ld.threshold = sqrt(0.1)
)
snp.pruned <- unlist(snpset, use.names = FALSE)
length(snp.pruned)

#   The output is a list the SNPs on each chromosome

#   (Roughly 180 SNPs are retained. Note that this procedure includes a random
#   process, so the number of SNPs selected will vary)


#   Now we calculate the PCs by applying snpgdsPCA, using only the pruned SNPs
#   and the samples selected earlier

pca <- snpgdsPCA(gdsobj, sample.id = sample.sel, snp.id = snp.pruned)
dim(pca$eigenvect)
head(pca$eigenvect)

#   The function returns a list of 8 objects, including the eigenvectors and the
#   ordered scanIDs

#   32 eigenvectors/PCs have been provided (in order); they're stored in
#   pca$eigenvect, a 43x32 matrix (43 samples by 32 eigenvectors)

```

## Part 5 - Report (PCAs)

* How many SNPs were used to calculate PCs?

    - `r length(snp.pruned)` used; (in my pruning trial, it was 177 SNPs)

* Make pairwise scatterplots of the first 4 PCs, using different plotting symbols for the two populations, as reported in the "race" variable in scanAnnot.

    - Plotted below

* Make a parallel coordinate plot for the first 4 plots as well, again distinguishing the plotted lines according to the "race" variable.

    - Plotted below

* What information does the first PC appear to convey?

    - The first PC explains the most variance of the genetic population structure, or here, separating the two populations. 
    - Based on the pairwise PC plot, we may only want to include the first PCs, because additional PCs do not provide more information than PC1 vs PC2.
    - Similarly, based on the paralleled coordinate plot, it is very clear for PC1 to separate the two populations, while other PCs are not really capturing the variance between the two.

```{r part4_report}

#   <Your code goes here>

#### pairwise scatterplots of the first 4 PCs

# extract the first 4 PCs
df_pca_plot = pca$eigenvect[,c(1:4)] %>% as.data.frame()
colnames(df_pca_plot) = c("PC1","PC2","PC3","PC4")
# add key for merge
df_pca_plot$scanID = pca$sample.id
# merge with scanAnnot
merged_pca_plot = 
    merge(x = pData(scanAnnot),
          y = df_pca_plot,
          by = "scanID",
          all.y = TRUE)
dim(merged_pca_plot)

# plot
# library(GGally) #suggested by chat-gpt
# ggpairs(merged_pca_plot, 
#         columns = 21:24,  # Assuming PC1-PC4 are the first 4 columns
#         aes(color = race),
#         upper=NULL, diag=NULL)


# df to store pc pairs
tmp_pc_pairs = data.frame("pair1"=rep(NA,16), pair2=NA)
row=1
for (i in seq(1:4)){
    for (j in seq(1:4)){
        if (row <= 16){
            tmp_pc_pairs[row,"pair1"] = i
            tmp_pc_pairs[row,"pair2"] = j
        }
        row = row +1
    }
}
filtered_pc_pairs = tmp_pc_pairs %>% filter(pair1<pair2)
filtered_pc_pairs$pair1 = paste0("PC", filtered_pc_pairs$pair1)
filtered_pc_pairs$pair2 = paste0("PC", filtered_pc_pairs$pair2)
print(filtered_pc_pairs) #ready for plotting

# loop through the target and make a plot
library(patchwork)
{
    p = NULL #setup canvas
    for (i in seq(nrow(filtered_pc_pairs))){
        canvas = merged_pca_plot %>% 
            ggplot(aes(x=.data[[ filtered_pc_pairs[i,"pair1"] ]],
                       y=.data[[ filtered_pc_pairs[i,"pair2"] ]], 
                       color=race)) +
            geom_point(size=3) + 
            theme_bw() + 
            labs(title=paste0(filtered_pc_pairs[i,"pair2"]," vs ",filtered_pc_pairs[i,"pair1"]))
        
        # control patchwork
        if (is.null(p)){
            p = canvas
        } else {
            p = p+canvas
        }
    }
    p #plot
}

#### Parellele coord plot
library(GGally)
ggparcoord(data = merged_pca_plot,
           columns = 21:24, 
           groupColumn = "race",
           showPoints = TRUE) + 
    scale_color_brewer(palette = "Set2") + 
    theme_bw()
#reference: https://r-charts.com/ranking/parallel-coordinates-ggplot2/

```

<br>

## Part 6 - Duplicate Sample Discordance

Here we leverage the duplicate samples to assess genotyping errors. If the same probe often yields different genotypes for duplicate scans from the same subjects, we should probably exclude the genotypes called from that probe. We will use the function `duplicateDiscordance`.

```{r discordance, eval=TRUE}

#   First, we should only use high-quality scans to when we judge the probes

scan.excl <- scanAnnot$scanID[scanAnnot$missing.e1 >= 0.05]
length(scan.excl)

#   (Recall that none of our scans had high missingness, so we don't have to
#   exclude anyone in this dataset)

#   We also don't want to bother testing for discordance in SNPs that are 100%
#   missing, so we exclude those, too

snp.excl <- snpAnnot$snpID[snpAnnot$missing.n1 == 1]
length(snp.excl)

#   Get the genotype data (make sure the connection to the file is closed before
#   reopening it)

#close(genoData)
showfile.gds(closeall = T, verbose = T)
genofile <-
  system.file("extdata", "illumina_geno.gds", package = "GWASdata")
genoGDS <- GdsGenotypeReader(genofile)

#   Attach the annotation to it (note that the sex/relatedness information were
#   "fixed" above)
genoData <-
  GenotypeData(genoGDS, snpAnnot = snpAnnot, scanAnnot = scanAnnot)

#   Now we use the dupdisc function to calculate the discordance for each SNP
#   (while excluding any low-quality scans and 100%-missing SNPs)
dupdisc <-
  duplicateDiscordance(
    genoData,
    subjName.col = "subjectID",
    scan.exclude = scan.excl,
    snp.exclude = snp.excl
  )

#   The function returns a list of 3 objects: discordance.by.snp,
#   discordance.by.subject, and correlation.by.subject

names(dupdisc)
dim(dupdisc$discordance.by.snp)
head(dupdisc$discordance.by.snp)
#   discordance.by.snp has a row for each SNP, detailing the number of
#   duplicate-pairs of scans observed for that SNP, the number of discordant
#   gentoypes observed among those pairs, and the discordance rate


length(dupdisc$discordance.by.subject)
#   discordance.by.subject is a list of matrices. For each subject with
#   duplicate scans, the matrix shows the discordance between the pairs of scans
#   (i.e., at what proportion of SNPs do two scans from the same person have
#   different genotypes?)

dupdisc$discordance.by.subject[[1]]
#   For the first subject in dupdisc$discordance.by.subject (scans 280/281), it
#   looks like the genotypes agreed for all the SNPs

dupdisc$discordance.by.subject[[2]]
#   For the second subject (scans 282/283), the discordance rate was
#   0.0003265839


#   Save a summary of this information by merging the discordances into the SNP
#   annotation

snpAnnot$dummy <- 1:nrow(pData(snpAnnot))
pData(snpAnnot) <-
  merge(
    x = pData(snpAnnot),
    y = dupdisc$discordance.by.snp[, c("snpID", "discordant")],
    all.x = T,
    all.y = F
  )

#   Make sure the order of the SNPs is maintained
pData(snpAnnot) <- pData(snpAnnot)[order(snpAnnot$dummy), ]

```

## Part 6 - Report

Briefly explain the purpose of this step and what it means to check for discordant genotypes. Summarize the results. Be sure to answer the following:

**The main idea of this step is to take advantage of the intended duplicates to check if the same sample's same probe would generate the same genotyping data. If not, then should drop both in real setting**

* How many SNPs are discordant in at least one duplicate-pair?

    - 25 SNPs!

```{r}
pData(snpAnnot) %>% filter(discordant >= 1) %>% nrow()
```

* What's the maximum number of discordances seen for any SNP?

    - 2 is the max number of discordances
    
```{r}
max(pData(snpAnnot)$discordant, na.rm=TRUE)
```

* What's the median discordance rate? What's the maximum discordance rate?

    - Median discordance rate = 0; Max discordance rate = 0.0741

```{r}
summary(dupdisc$discordance.by.snp$discord.rate)
```


* Decide and explicitly state the threshold, n, for filtering out SNPs based on discordance (i.e., SNPs with dupdisc$discordance.by.snp >= n will be removed)

    - SNPs with dupdisc$discordance.by.snp >= 1 will be removed. 
    - We recommend a filter threshold of **â¥1** discordant calls because this retains >99% of SNPs with an error rate < 10â»Â³, while removing >14.8% of SNPs with an error rate > 10â»Â². This threshold eliminates x SNPs.
    
```{r}
table(dupdisc$discordance.by.snp$npair) #most SNPs have 34 duplicate samples

#method1
pbinom(q=1, size=2*34, prob=1e-2, lower.tail=FALSE) #0.1483238

#method2
duplicateDiscordanceProbability(npair=34, error.rate = c(1e-3, 1e-2), max.disc = 2)
#dis>1 2.147291e-03 1.459858e-01

```
    * You may find it helpful to call the function duplicateDiscordanceProbability(npair=34). Read the documentation for this function.


* Of the SNPs pass that passed the missing.n2 filter (missing.n2 < 0.05), how many SNPs pass/fail the discordance threshold?

    - We still recommend using >=1 discordant pair as a threshold of with the same reason above. In this case (using missing.n2 as threshold), **21 SNPs were filtered** (â¥ 1 discordant pairs), and 3074 SNPs passed.

```{r}
snp_exclude2 = snpAnnot$snpID[snpAnnot$missing.n2 >= 0.05]
length(snp_exclude2) #205 filtered

# recalc dupl-statistics
dupdisc_MissingN2 <-
  duplicateDiscordance(
    genoData,#same
    subjName.col = "subjectID",
    scan.exclude = scan.excl,
    snp.exclude = snp_exclude2
  )

table(dupdisc_MissingN2$discordance.by.snp$npair) #still d=34

#### so we still use a threshold of >=1

# find # of SNPs pass/fail
length(dupdisc_MissingN2$discordance.by.snp$snpID) #total 3095 SNPs

sum(dupdisc_MissingN2$discordance.by.snp$discordant==0) #3074 SNPs passed
sum(dupdisc_MissingN2$discordance.by.snp$discordant>=1) #  21 SNPs failed

```


* Of the SNPs with missing.n2 < 0.05, make a histogram of the discordance rate

```{r}
hist(dupdisc_MissingN2$discordance.by.snp$discord.rate,
     xlab="discordance rate", main="Histogram of discordance rate \nof the SNPs with missing.n2 < 0.05")
```


* Make sure you add a new column to snpAnnot called failed.dup.disc ("pass" if the SNP had >=n discordant calls, "fail" if it failed, "untested" if it was one of the high-missingness SNPs that we excluded); update the metadata

```{r part5_report}

#   <Your code goes here>

#### Update snpAnnot ####
pData(snpAnnot) = pData(snpAnnot) %>% 
    mutate(failed.dup.disc = 
               case_when(
                   (discordant >= 1) & !(snpID %in% snp.excl) ~ "fail",
                   (discordant == 0) & !(snpID %in% snp.excl) ~ "pass",
                   snpID %in% snp.excl ~ "untested")
           )

#checks
pData(snpAnnot) %>% filter(failed.dup.disc=="untested") %>% select(discordant, failed.dup.disc) %>% distinct()

pData(snpAnnot) %>% filter(failed.dup.disc=="fail") %>% nrow()


#### Update the metaData ####
varMetadata(snpAnnot)["failed.dup.disc", "labelDescription"] = 
    "{fail,pass,untested}: 'fail' are the tested variants with at least 1 discordant pairs; 'pass' are the tested variants with no discordant pair; 'untested' are the variants whose missing rate is above missing.n1 and not get tested in this step."

varMetadata(snpAnnot) %>% slice(nrow(varMetadata(snpAnnot)))
```

## Part 7 - Hardy-Weinberg Equilibrium (HWE) testing

Deviations from HWE can indicate poor genotyping. Here you will appropriately test for departures from HWE in the data using `exactHWE` (which applies Fisher's exact test).

```{r hwe, eval=TRUE}

#   The test we'll use for HWE will assume independent observations

#   Therefore we should include only one scan from each subject

#   We should also include only "founders" (for this example, that means
#   excluding the children, whose genotypes aren't independent of their
#   parents')

#   The nonfounders are the individuals who have a mother or father in the
#   pedigree

head(pData(scanAnnot)[, c("father", "mother")])
nonfounders <- scanAnnot$father != 0 & scanAnnot$mother != 0
table(nonfounders)

#   HWE is sensitive to population stratification (A SNP can be in HWE in each
#   of two populations, but out of HWE in the combined population)

#   Therefore in this example we'll focus on HWE in just one population group,
#   the "CEU" group

#   So we'll exclude populations other than CEU, nonfounders, and duplicates
#   (recall tha that the "duplicated" variable was defined to include the scan
#   with better missingness for each subject)

scan.excl <-
  scanAnnot$scanID[scanAnnot$race != "CEU" |
                     nonfounders | scanAnnot$duplicated]
length(scan.excl)

#   Now we use exactHWE to calculate HWE statistics

#   We do this separately for the sex chromosomes

chr <- getChromosome(genoData)
auto <- range(which(chr %in% 1:22))
X <- range(which(chr == 23))

#   exactHWE takes snpStart/snpEnd arguments; we use these to identify the
#   indices corresponding to autosomal/sex chromosome SNPs

hwe <-
  exactHWE(
    genoData,
    scan.exclude = scan.excl,
    snpStart = auto[1],
    snpEnd = auto[2]
  )
hweX <-
  exactHWE(
    genoData,
    scan.exclude = scan.excl,
    snpStart = X[1],
    snpEnd = X[2]
  )

#   We use the scan.exclude argument to exclude non-CEU, non-founders, and duplicates

#   exactHWE has returned a data frame of HWE statistics for each SNP; read the help page to see what the columns are

#   Attach the two data frames
hwe <- rbind(hwe, hweX)
names(hwe)
#close(genoData)


#   Check on sample sizes for autosomes
hwe$N <- hwe$nAA + hwe$nAB + hwe$nBB #total genotypes
summary(hwe$N[is.element(hwe$chr, 1:22)]) #N = 17 

#   ... and for the X chromosome
summary(hwe$N[is.element(hwe$chr, 23)]) #N=8


#   Notice there are some missing p-values for the autosomes
#   ... and for X

#   We can view some of the genotype counts

#   The first SNP appears to be 100% missing, and the second is monomorphic
#   (i.e., MAF=0)

#   (recall that we didn't filter out SNPs here)

hwe$pval[1:10]
sum(is.na(hwe$pval[hwe$chr == 23]))
head(hwe[, c("nAA", "nAB", "nBB")])


#   Now we want to inspect deviation from HWE

#   We can use Q-Q plots to help with this

#   We should exclude monomorphic SNPs
hwe.0 <- hwe[hwe$MAF > 0, ]
dim(hwe.0)

##   Only keep the autosomal SNPs for first plot
pval <- hwe.0$pval[is.element(hwe.0$chr, 1:22)]
length(pval)

#   Double-check that there are no missing p-values remaining
pval <- pval[!is.na(pval)]
length(pval)


##   Similarly, get the p-values for the X-chromosome
pval.x <- hwe.0$pval[is.element(hwe.0$chr, 23)]
length(pval.x)
pval.x <- pval.x[!is.na(pval.x)]
length(pval.x)


####   Now make Q-Q plots
par(mfrow = c(2, 2))
qqPlot(pval = pval,
       truncate = FALSE,
       main = "Autosomes, all")
qqPlot(pval = pval,
       truncate = TRUE,
       main = "Autosomes, truncated")
qqPlot(pval = pval.x,
       truncate = FALSE,
       main = "X chromosome, all")
qqPlot(pval = pval.x,
       truncate = TRUE,
       main = "X chromosome, truncated")
par(mfrow = c(1, 1))

```

## Part 7 - Report

Briefly explain the purpose of HWE testing. In describing your results for this step, answer the following:

* How do you choose what subjects to include for HWE testing? How many were used here?

    - Since the HWE test assumes the input being indendent, and HWE can be sensitive for population structure, we want to only include founders with one scan per founder, also stratifying by population/race. 
    - Using this scheme, we excluded 60 scans, meaning that there were 17 scans used in HWE test here.

* Interpret the Q-Q plots. Do any SNPs appear to be strongly out of HWE? Which SNPs? What are the lowest p-values?

    - The QQ plots compare two distributions of -log10(P), i.e., expected p vs observed p. Each dot is a SNP, and if they follow the red-line and fall within the grey area (Confidence Interval), that means that they do not deviate from the HWE. However, if they deviate from the expected p-value distribution a lot (from the red line), that is an violation of HWE, indicating an issue. 
    - For autosomes, most SNPs aligned with the red line well (indicating most of them are under HWE), except for a few signals at the tail (with 1 very extreme signal), indicating that those SNPs violated the HWE (true signals). For that 1 specific SNP, it is snpID = 1015218, and it has the lowest p-value of 5.616715e-05 for autosome SNPs.
    - For X chromosome, there is a larger deviation from the red line, but mostly they are below the line, indicating lack of power, which is not a big concern. This makes sense potentially because of that only females were included but not males. There is NO SNPs being strongly out of HWE, the lowest p-value is 0.01538462.
    
```{r}
unique(hwe.0$chr)

#### Autosomes
hwe.0 %>% filter(chr != 23) %>%
    filter( !is.na(pval) ) %>%
    arrange(pval)

#### X chr
hwe.0 %>% filter(chr == 23) %>% 
    filter( !is.na(pval) ) %>%
    arrange(pval)

```
    
* For the autosomal SNPs, make a plot of -log10(p-value) vs MAF. Make another such plot for the X chromosome.

```{r}
#### Autosomes
hwe.0 %>% filter(chr != 23) %>%
    filter( !is.na(pval) ) %>%
    ggplot(aes(x=MAF, y = -log10(pval) )) + 
    geom_point() + 
    theme_bw()

#### X chr
hwe.0 %>% filter(chr == 23) %>% 
    filter( !is.na(pval) ) %>%
    ggplot(aes(x=MAF, y = -log10(pval) )) + 
    geom_point() + 
    theme_bw()

```


* What p-value will you use for filtering our SNPs with low HWE? Of the SNPs with missing.n2 < 0.05, how many will be retained/removed?

    - Based on the -log10(p-value) vs MAF and the QQ plot above, I would choose a threshold at -log10(p-value) > 2 (i.e., p-value < 0.01), given that most data points below this line are randomly distributed. 
    - Other commonly use threshold is 1e-4
    - If using p-value < 0.01 as a threshold, among the 2455 SNPs that passed the missing.n2 < 0.05 filter, **we get 1 SNP removed (snpID = 1015218)**, and the rest 2454 SNPs were kept. 
    
```{r}
#### Autosomes
snpid_kept_missingN2 = pData(snpAnnot) %>% filter(missing.n2 < 0.05) %>% pull(snpID)

#Of the SNPs with missing.n2 < 0.05, total = 2455
hwe.0 %>% filter(snpID %in% snpid_kept_missingN2) %>% 
    filter(pval < 0.01)
    
```
    
* Add the HWE p-values to the SNP annotation (and update the metadata)

```{r part6_report}

#   <Your code goes here>

#### Update the snpAnnot
pData(snpAnnot) = 
    merge(x = pData(snpAnnot), 
          y = hwe.0 %>% select(snpID, pval), 
          by = "snpID", 
          all.x = TRUE, all.y = FALSE) %>%
    rename(HWE.pval = pval)

# checks
pData(snpAnnot) %>% filter( !is.na(HWE.pval) ) %>% nrow()
hwe.0 %>% select(snpID, pval) %>% filter( !is.na(pval) ) %>% nrow()

#### Update the metaData
varMetadata(snpAnnot)["HWE.pval", "labelDescription"] = 
    "p-value obtained from HWE Exact test, after excluding populations other than CEU, nonfounders, and duplicates (exclude_scan_n_total = 60), and after removing the monomorphic & missing SNPs leaving 1785 autosome SNPs left and 700 sex chromosome SNPs left (in total 2485 SNPs) in the calculation."

varMetadata(snpAnnot)

```

<br>

```{r}
sessionInfo()
```

